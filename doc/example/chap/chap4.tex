\chapter{Spine decompositions of non-presistent superprocesses: characteristic functions}
\section{Introduction}
\subsection{Motivation}
    Consider a general $(\xi,\psi)$-superprocess $\{(X_t)_{t\geq 0}, \mathbf P_\mu\}$ in a loccally compact seperable metric space $E$.
    Note that, in the previous chapter, we always take a non-negative testing function $f$ and study the property of $\langle f,X_t\rangle$.
    In this case, $\langle f, X_t\rangle$ is also non-negative, and therefore its distribution property can be captured by its Laplace transform 
\[
    \mathbb P_{\delta_x}[e^{-\theta\langle f,X_t\rangle}],\quad t\geq 0, \theta \geq 0, x\in E.
\] 
    The difinition of the superprocess [??] says that the map $(t,x)\mapsto \mathbb P_{\delta_x}[e^{- \langle f,X_t\rangle}]$ is the unique locally bounded non-negative solution to a mild non-linear partial differential equation [?]
    Therefore, several distributional properties of $\langle f, X_t\rangle$ can be obtained by taking advantage of these equations.

    A natural question arises in studying the limiting theory for superprocesses is to consider the property of $\langle f,X_t\rangle$ where $f$ is a Borel measurable function on $E$ which may take both non-negative and negative values.
    Note that when $f$ is bounded, $\langle f,X_t\rangle$ is a well defined random variable whose Laplace trassform may not exists. 
    So we can't use the equation () derictly anymore.
    Instead, we consider the characteristic function of $\langle f,X_t\rangle$:
\[
    \mathbb P_{\delta_x}[e^{-i\theta \langle f,X_t\rangle}],\quad t\geq 0, x\in E, \theta \geq 0,
\]
    and ask the question: whether map $(t,x)\mapsto \mathbb P_{\delta_x}[e^{i\langle f,X_t\rangle}]$ also satisfies some mild complex-valued non-linear partial differential equation.

    In this cahpter, we give a positive answere to this question under a non-presistent assumption.
    The precise statements of the results and the assumptions are postponed in the next subsection.
    We mention here that our key tool is the general spine decomposition theorem for the superprocesses developed in the previous chapter. 
    This is one of the evidence that the spine theory really captures the distributional porperties of the superprocesses. 

\subsection{Main result}
	
	We repeat our settings for the superprocesses in this chapter because they are more general than Chapter (2?).
    Let $E$ be locally compact separable metric space. Denote by $\mathcal M(E)$ the collection of all the finite measures on $E$ equipped with the topology of weak convergence.
    For each function $F(x,z)$ on $E\times \mathbb R_+$ and each $\mathbb R_+$-valued function $f$ on $E$, we use the following convention:
\[
    F(x,f):= F(x,f(x)),\quad x\in E.
\]
    A process $X=\{(X_t)_{t\geq 0}; (\mathbf P_\mu)_{\mu \in \mathcal M(E)}\}$ is said to be a $(\xi,\psi)$-superprocess if
\begin{itemize}
\item
    The spatial motion $\xi=\{(\xi_t)_{t\geq 0};(\Pi_x)_{x\in E}\}$ is an $E$-valued Hunt process with its lifetime denoted by $\zeta$.
\item
    The branching mechanism $\psi: E\times[0,\infty) \to \mathbb R$ is given by
\begin{equation}
\label{eq: branching mechanism}
    \psi(x,z)=
    -\beta(x) z + \alpha (x) z^2 + \int_{(0,\infty)} (e^{-zy} - 1 + zy) \pi(x,dy).
\end{equation}
    where $\beta \in \mathcal B_b(E)$, $\alpha \in \mathcal B_b(E, \mathbb R_+)$ and $\pi(x,dy)$ is a kernel from $E$ to $(0,\infty)$ such that $\sup_{x\in E} \int_{(0,\infty)} (y\wedge y^2) \pi(x,dy) < \infty$.
\item
    $X=\{(X_t)_{t\geq 0}; (\mathbf P_\mu)_{\mu \in \mathcal M(E)}\}$ is an $\mathcal M(E)$-valued Hunt process with transition probability determined by
\begin{equation}
    \mathbf P_\mu [e^{-X_t(f)}] = e^{-\mu(V_tf)},
    \quad t\geq 0, \mu \in \mathcal M(E), f\in \mathcal B^+_b(E),
\end{equation}
    where for each $f\in \mathcal B_b(E)$, the function $(t,x)\mapsto V_tf(x)$ on $[0,\infty) \times E$ is the unique locally bounded positive solution to the equation
\begin{equation}\label{eq:FKPP_in_definition}
    V_tf(x) + \Pi_x \Big[  \int_0^{t\wedge \zeta} \psi(\xi_s,V_{t-s}f)ds \Big]
    = \Pi_x [ f(\xi_t)\mathbf 1_{t<\zeta} ],
    \quad t \geq 0, x \in E.
\end{equation}
\end{itemize}
    We refer our readers to \cite{Li2011Measure-valued} for more discussions about the definition and the existence of superprocesses.
    To avoid triviality, we assume that
    $\psi(x,z)$ is not identically equal to $-\beta(x)z$.

    We say $X$ is non-persistent if $\mathbf P_{\delta_x}(\|X_t\| = 0)>0$ for all $x\in E$ and $t >0$. 
    In this chapter, we will always assume that our superprocess $X$ is non-persistent.

    Let $\mathbb C_+:=\{x+iy:x\geq 0, y\in \mathbb R\}$ and $\mathbb C_+^0:=\{x+iy: x>0, y\in \mathbb R\}$.
    The branching mechanism $\psi$ can be extended into a map from $E \times \mathbb C_+$ to $\mathbb C$ using Lemma \ref{lem: extension lemma for branching mechanism} below in the sense that for each $x\in E$, $z\mapsto \psi(x,z)$ is a holomorphic funcion on $\mathbb C_+^0$ and continuous on $\mathbb C_+$.
    Define
\begin{equation}
    \psi'(x,z):= - \beta(x) + 2\alpha(x) z + \int_{(0,\infty)} (1-e^{-zy})y\pi(x,dy),
    \quad x\in E, z\in \mathbb C_+.
\end{equation}
    It will be proved in Lemma \ref{lem: extension lemma for branching mechanism} below that for each $x \in E$, $z \mapsto \psi(x,z)$ is a holomorphic function on $\mathbb C_+^0$ with derivative $z \mapsto \psi'(x,z)$.
    Write $\psi_0(x,z) := \psi(x,z)+ \beta(x)z $ and $\psi'_0(x,z) := \psi'(x,z) + \beta(x)$.

    Define
\begin{align}
    L_1(\xi)
    &:= \{f\in \mathcal B(E): \forall x\in E, t\geq 0, \quad \Pi_x[|f(\xi_t)|]< \infty\},
    \\L_2(\xi)
    &:= \{f \in \mathcal B(E): |f|^2 \in L_1(\xi)\}.
\end{align}
    The mean behavior of the superprocess is well known:
\begin{equation}   
    \mathbf P_{\delta_x}[\langle f, X_t\rangle]
    =P^{\beta}_t f(x):= \Pi_x[e^{\int_0^t \beta(\xi_s)ds}f(\xi_t)\mathbf 1_{t < \zeta}] \in \mathbb R,
    \quad f\in L_1(\xi), t \geq 0,x\in E.
\end{equation}
    This also says that the random variable $\langle X_t, f\rangle$ is well defined under probability $\mathbf P_{\delta_x}$ provided $f\in L_1(\xi)$.
    By the branching property of the superprocess, $\langle X_t, f\rangle$ is an infinitely divisible random variable.
    Therefore, for fixed $x\in E, t\geq 0$ and $f\in L_1(\xi)$, there exists a unique continuous map $\theta \mapsto U_t(\theta f)(x)$ from $\mathbb R$ to $\mathbb C$ such that $\mapsto U_t(0\cdot f)(x) = 0$ and
\[
    e^{U_t(\theta f)(x)} = \mathbf P_{\delta_x}[e^{i\theta \langle X_t,f\rangle}].
\]
    This map is known as the characteristic exponent of the infinitely divisible random variable $\langle X_t,f\rangle$ under probability $\mathbf P_{\delta_x}$. 
    See the paragraph immediately after \cite[Lemma 7.6]{Sato2013Levy}.

    The main result in this chapter is the following:
\begin{prop}
\label{prop: complex FKPP-equation}
    If $f\in L_2(\xi)$,  then for all $t\geq 0$ and $x\in E$,
\begin{equation}
\label{eq: complex FKPP-equation}
    U_tf(x) - \Pi_x \Big[\int_0^t \psi\big(\xi_s, - U_{t-s}f\big) ds \Big]
    \\= i \Pi_x [f(\xi_t)]
\end{equation}
    and
\begin{equation}
\label{eq: complex FKPP-equation with FK-transform}
    U_tf(x) -  \int_0^t P_{t-s}^{\beta} \psi_0\big(\cdot,-U_sf\big) (x)~ds
    \\= iP_t^{\beta} f(x).
\end{equation}
\end{prop}

\subsection{Some words before the proofs}
	At first glance of the above Proposition, one might think a natural way of proving it is to consider decomposing the general text function $f$ into its positive and negative parts:
\[
	f= f^+ -f^-
\]
	and try to prove the proposition for each $f^\pm$ using Equation (?) and maybe the theory of holomorphic extensions.
	However, we think this strategy will not work, because the dependence between $\langle f^+,X_t\rangle$ and $\langle f^-,X_t\rangle $ is not clear. (Note in particular, they are not independent.) so we don't know the relation between $(U_tf^+,U_tf^-)$ and $U_tf$.

	Instead, our strategy is to use the general spine decomposition theory developed in the previous chapter. 
	The underlying idea is very simple: since the spine decomposition theory gives a decomposition about the superprocess $X_t$, it also gives a decomposition of $\rangle f,X_t\rangle$. 
	Translating this decomposition for random variable $\langle f,X_t\rangle$ in the laguage of characteristic functions will give us some complex valued indentities. 
	Using those indentities we should be able to verify Proposition (?).

	This is also the reason why we need the assume that the superprocess is non-presistent, because this is required by the general spine decomposition theorem. 

\section{Preliminary}
\subsection{Some analytic facts}
    In this subsection, we collect some useful analytic facts.
\begin{lem}
\label{lem: estimate of exponential remaining}
    For $z\in \mathbb C_+$,  we have
\begin{equation}
\label{eq: estimate of exponential remaining}
    \Big|e^{-z} - \sum_{k=0}^n \frac{(-z)^k}{k!} \Big|
    \leq \frac{|z|^{n+1}}{(n+1)!} \wedge \frac{2|z|^{n}}{n!}, \quad n\in \mathbb Z_+.
\end{equation}
\end{lem}
\begin{proof}
    Notice that $|e^{-z}| = e^{- \operatorname{Re} z} \leq 1$.
    Therefore,
\begin{equation}
    |e^{-z} - 1|
    = \Big| \int_0^1 e^{-\theta z} z d\theta\Big|
    \leq |z|.
\end{equation}
    Also, notice that $|e^{-z} - 1| \leq |e^{-z}|+1 \leq 2$.
    Thus \eqref{eq: estimate of exponential remaining} is true when $n = 0$.
    Now, suppose that \eqref{eq: estimate of exponential remaining} is true when $n = m$ for some $m \in \mathbb Z_+$.
    Then
\begin{align}
    &\Big|e^{-z} - \sum_{k=0}^{m+1} \frac{(-z)^k}{k!}\Big|
    = \Big| \int_0^1\Big(e^{-\theta z} - \sum_{k=0}^m \frac{(-\theta z)^k}{k!} \Big) z d\theta \Big|
    \\&\quad \leq  \Big(\int_0^1 \frac{|\theta z|^{m+1}}{(m+1)!} |z| d\theta\Big) \wedge \Big(\int_0^1 \frac{2|\theta z|^{m}}{m!} |z| d\theta\Big)
    = \frac{|z|^{m+2}}{(m+2)!} \wedge \frac{2|z|^{m+1}}{(m+1)!},
\end{align}
    which says that \eqref{eq: estimate of exponential remaining} is true for $n = m + 1$.
\end{proof}

\begin{lem}
\label{lem: extension lemma for branching mechanism}
    Suppose that  $\pi$ is a measure on $(0,\infty)$ with $\int_{(0,\infty)} (y \wedge y^2) \pi(dy)< \infty$.
    Then the functions
\begin{equation}
    h (z) = \int_{(0,\infty)} (e^{-zy} - 1 + zy) \pi(dy), \quad z \in \mathbb C_+
\end{equation}
    and
\begin{equation}
\label{eq: deriavetive of the Poission partb}
    h'(z) = \int_{(0,\infty)}(1- e^{-zy})y \pi(dy), \quad z \in \mathbb C_+
\end{equation}
    are well defined, continuous on $\mathbb C_+$ and holomorphic on $\mathbb C_+^0$.
    Moreover,
\[
    \frac{h(z)-h(z_0)}{z-z_0} \xrightarrow[\mathbb C_+\ni z \to z_0]{} h'(z_0),\quad z_0 \in \mathbb C_+.
\]
\end{lem}
\begin{proof}
    It follows from Lemma \ref{lem: estimate of exponential remaining} that $h$ and $h'$ are well defined on $\mathbb C_+$.
   According to \cite[Theorems 3.2. \& Proposition 3.6]{SchillingSongVondracek2010Bernstein}, 
    $h'$ is continuous on $\mathbb C_+$ and holomorphic on $\mathbb C_+^0$.

    It follows from Lemma \ref{lem: estimate of exponential remaining} that, for each $z_0 \in \mathbb C_+$,  there exists $C>0$ such that for $z \in \mathbb C_+$ close enough to $z_0$ and any
    $y>0$,
\begin{align}
    &\Big| \frac{e^{-zy} - e^{-z_0 y}+(z-z_0) y}{z-z_0} \Big|
    = \frac{1}{|z-z_0|}\Big| \int_0^1 \big(-y e^{-(\theta z+(1-\theta)z_0)y}+y\big)(z-z_0)d\theta\Big|
    \\ &\leq y\int_0^1 |1-e^{-(\theta z +(1-\theta)z_0)y}| d\theta
    \leq (2y) \wedge\Big( y^2\int_0^1|\theta z+(1-\theta)z_0|d\theta\Big)
    \leq C(y\wedge y^2).
\end{align}
    Using this and the dominated convergence theorem, we have
\begin{align}
    &\frac{h(z)-h(z_0)}{z-z_0} = \int_{(0,\infty)} \frac{e^{-zy}+zy -(e^{-z_0 y}+z_0 y)}{z-z_0}  \pi(dy)
    \\&\xrightarrow[\mathbb C_+\ni z\to z_0]{} \int_{(0,\infty)}(1 - e^{-z_0 y} )y\pi(dy) = h'(z_0),
\end{align}
    which says that $h$ is continuous on $\mathbb C_+$ and holomorphic on $\mathbb C_+^0$.
\end{proof}

    For each $z\in \mathbb C\setminus (-\infty,0]$, we define
$
    \log z := \log |z| + i \arg z
$
    where $\arg z \in (-\pi,\pi)$ is uniquely determined by
$
    z = |z|e^{i \arg z}.
$   
    For all $z\in \mathbb C\setminus (-\infty,0]$ and $\gamma \in \mathbb C$, we define
$
    z^\gamma := e^{\gamma \log z}.
$
    Then it is known, see \cite[Theorem 6.1]{SteinShakarchi2003Complex} for example, that $z\mapsto \log z$ is holomorphic in $\mathbb C\setminus (-\infty,0]$.
    Therefore, for each $\gamma \in \mathbb C$, $z\mapsto z^\gamma$ is holomorphic in $\mathbb C\setminus (-\infty,0]$. (We use the convention that  $0^\gamma := \mathbf 1_{\gamma = 0}$.)
    Using the definition above we can easily show that $(z_1z_0)^\gamma = z_1^\gamma z_0^\gamma$ provided $\arg (z_1z_0)=\arg (z_1) + \arg(z_0)$.

    Recall that the Gamma function  $\Gamma$ is defined by
\begin{equation}
    \Gamma (x) := \int_0^\infty t^{x-1} e^{-t}dt,
    \quad x>0.
\end{equation}
    It is known, see, for instance, \cite[Theorem 6.1.3]{SteinShakarchi2003Complex} and the remark following it, that the function $\Gamma$ has an unique analytic extension in $\mathbb C\setminus\{0, -1,-2,\dots\}$ and that
\[
    \Gamma(z+1) = z \Gamma(z),\quad z\in \mathbb C\setminus\{0, -1,-2,\dots\}.
\]
    Using this recursively, one gets that
\begin{equation}
\label{eq: definition of Gamma function}
    \Gamma(x)
    := \int_0^\infty t^{x-1} \Big(e^{-t} - \sum_{k=0}^{n-1} \frac{(-t)^k}{k!}\Big) dt,
    \quad -n< x< -n+1, n\in \mathbb N.
\end{equation}

    Fix a $\beta \in (0,1)$.
    Using the uniqueness of holomorphic extension and Lemma \ref{lem: extension lemma for branching mechanism}, we get that
\begin{equation}
    z^{\beta}
    = \int_0^\infty (e^{-zy}-1) \frac{dy}{\Gamma(-\beta)y^{1+\beta}},
    \quad z\in \mathbb C_+,
\end{equation}
    by showing that the both sides
\begin{itemize}
\item
    are extension of the real function $x\mapsto x^{\beta}$ defined on $[0,\infty)$;
\item
    are holomorphic on $\mathbb C_+^0$;
\item
    are continuous on $\mathbb C_+$.
\end{itemize}
    Similarly, we get that
\begin{equation}
\label{eq: stable branching on C+}
    z^{1+\beta}
    = \int_0^\infty (e^{-zy}-1+zy)\frac{dy}{\Gamma(-1-\beta)y^{2+\beta}},
    \quad z\in \mathbb C_+.
\end{equation}
    Lemma \ref{lem: extension lemma for branching mechanism} also says that the derivative of $z^{1+\beta}$ is $(1+\beta)z^{\beta}$ on $\mathbb C^0_+$.
\begin{lem}
\label{lem: Lip of power function}
    For all $z_0,z_1 \in \mathbb C_+$, we have
\begin{equation}
\label{eq: Lip of power function}
    |z_0^{1+\beta} - z_1^{1+\beta}|
    \leq (1+\beta)(|z_0|^{\beta}+|z_1|^{\beta})|z_0 - z_1|.
\end{equation}

\end{lem}
\begin{proof}
    Since $z^{1+\beta}$ is continuous on $\mathbb C_+$, we only need to prove the lemma assuming $z_0,z_1 \in \mathbb C^0_+$.
    Notice that
\begin{equation}
\label{eq: upper bound for beta power of z}
    |z^\beta|
    = |e^{\beta \log |z| +i\beta \operatorname {arg}z}| = e^{\beta \log |z|} = |z|^\beta,
    \quad z \in \mathbb C\setminus (-\infty, 0].
\end{equation}
    Define a path $\gamma: [0,1] \to \mathbb C^0_+$ such that
\[
    \gamma(\theta)
    = z_0 (1-\theta) + \theta z_1,
    \quad \theta \in [0,1].
\]
    Then, we have
\begin{align}
    |z_0^{1+\beta} - z_1^{1+\beta}|
    &\leq (1+\beta) \int_0^1 |\gamma(\theta)^{\beta}|\cdot |\gamma'(\theta)|d\theta
    \leq (1+\beta)  \sup_{\theta \in [0,1]} |\gamma(\theta)|^{\beta} \cdot |z_1-z_0|
    \\&\leq (1+\beta)  ( |z_1|^{\beta}+|z_0|^{\beta} ) |z_1-z_0|.
    \qedhere
\end{align}
\end{proof}

    Suppose that $\varphi(\theta)$ is a continuous function from $\mathbb R$ into $\mathbb C$ such that $\varphi(0) = 1$ and $\varphi(\theta) \neq 0$ for all $\theta \in \mathbb R$.
    Then according to \cite[Lemma 7.6]{Sato2013Levy}, there is a unique continuous function $f(\theta)$ from $\mathbb R$ into $\mathbb C$ such that $f(0) = 0$ and $e^{f(\theta)} = \varphi(\theta)$.
    Such a function $f$ is called the distinguished logarithm of the function $\varphi$ and is denoted as $\operatorname{Log} \varphi(\theta)$.
    In particular, when $\varphi$ is the characteristic function of an infinitely divisible random variable $Y$,  $\operatorname{Log} \varphi(\theta)$ is called the L\'evy exponent of $Y$.
    This distinguished logarithm should not be confused with the $\log$ function defined on $\mathbb C\setminus (-\infty, 0]$.
    See the paragraph immediately after \cite[Lemma 7.6]{Sato2013Levy}.

\subsection{Feynman-Kac formula with complex valued functions}
\label{seq: complex Feynman-Kac transform}
    In this subsection we give a version of the Feynman-Kac formula with complex valued functions.
    Suppose that $\{(\xi_t)_{t \in [r,\infty)}; (\Pi_{r,x})_{r\in [0,\infty), x\in E}\}$ is a (possibly non-homogeneous) Hunt process in a locally compact separable metric space $E$.
    We write
\begin{equation}
    H^{(h)}_{(s,t)}
    := \exp\Big\{\int_s^t h(u,\xi_u) du\Big\},
    \quad 0 \leq s \leq t, h \in \mathcal B_b([0,t] \times E,\mathbb C).
\end{equation}

\begin{lem}
\label{eq: complex FK}
    Let $t \geq 0$. Suppose that
    $\beta, \alpha\in \mathcal B_b([0,t] \times E, \mathbb C)$
    and $f\in \mathcal B_b(E, \mathbb C)$.
    Then
\begin{equation}
\label{eq: expresion of g}
    g(r,x) := \Pi_{r,x}[ H_{(r,t)}^{(\beta+\alpha)} f(\xi_t)],\quad r \in [0,t], x\in E,
\end{equation}
    is the unique locally bounded solution to the equation
\[
    g(r,x)= \Pi_{r,x} [ H_{(r,t)}^{(\beta)} f(\xi_t)]+\Pi_{r,x} \Big[ \int_r^tH_{(r,s)}^{(\beta)}\alpha(s,\xi_s) g(s,\xi_s)~ds \Big],\quad r \in [0,t], x\in E.
\]
\end{lem}

\begin{proof}
    The proof is similar to that of \cite[Lemma A.1.5]{Dynkin1993Superprocesses}. We include it here for the sake of completeness.
    We first verify that \eqref{eq: expresion of g} is a solution.
    Notice that
\begin{equation}
   \Pi_{r,x} \Big[ \int_r^t | H_{(r,t)}^{(\beta)}\alpha(s,\xi_s) H_{(s,t)}^{(\alpha)} f(\xi_t)| ~ds \Big]
    \leq  \int_r^t e^{(t-r)\|\beta\|_\infty}e^{(t-s)\|\alpha\|_\infty}\|\alpha\|_\infty\|f\|_\infty ~ds
    < \infty.
\end{equation}
    Also notice that
\begin{equation}
\label{eq: crucial for Feynman-Kac}
    \frac{\partial}{\partial s} H^{(\alpha)}_{(s,t)}= -H^{(\alpha)}_{(s,t)}\alpha(s,\xi_s),
    \quad s\in (0,t).
\end{equation}
    Therefore, from the Markov property of $\xi$ and Fubini's theorem we get that
\begin{align}
    &\Pi_{r,x} \Big[ \int_r^tH_{(r,s)}^{(\beta)}~(\alpha g)(s,\xi_s)~ds \Big]
    =\Pi_{r,x} \Big[ \int_r^t H_{(r,s)}^{(\beta)}\alpha(s,\xi_s) \Pi_{s,\xi_s}[ H_{(s,t)}^{(\beta+\alpha)} f(\xi_t)]~ds \Big]
    \\&= \Pi_{r,x} \Big[ \int_r^t H_{(r,t)}^{(\beta)}\alpha(s,\xi_s) H_{(s,t)}^{(\alpha)} f(\xi_t) ~ds \Big]
    = \Pi_{r,x} [ H_{(r,t)}^{(\beta)}f(\xi_t)(H_{(r,t)}^{(\alpha)} - 1)]
    \\&= g(r,x) - \Pi_{r,x} [ H_{(r,t)}^{(\alpha)} f(\xi_t)].
\end{align}
    For uniqueness, suppose  $\tilde g$ is another solution. Put $h(r) = \sup_{x\in E}|g(r,x) - \tilde g(r,x)|$. Then
\[
   h(r) \leq e^{t\|\beta\|_\infty}\|\alpha\|_\infty \int_r^t h(s)ds,
    \quad r\le t.
\]
Applying Gronwall's inequality, we get that $h(r) =  0$ for $r\in [0,t]$.
\end{proof}


\subsection{Kuznestov measure}
\label{sec: definition of superprocess}
\begin{comment}    
    In this subsection, we will give the definition of a general superprocess.
    Let $E$ be locally compact separable metric space. Denote by $\mathcal M(E)$ the collection of all the finite measures on $E$ equipped with the topology of weak convergence.
    For each function $F(x,z)$ on $E\times \mathbb R_+$ and each $\mathbb R_+$-valued function $f$ on $E$, we use the following convention in this subsection:
\[
    F(x,f):= F(x,f(x)),\quad x\in E.
\]
    A process $X=\{(X_t)_{t\geq 0}; (\mathbf P_\mu)_{\mu \in \mathcal M(E)}\}$ is said to be a $(\xi,\psi)$-superprocess if
\begin{itemize}
\item
    The spatial motion $\xi=\{(\xi_t)_{t\geq 0};(\Pi_x)_{x\in E}\}$ is an $E$-valued Hunt process with its lifetime denoted by $\zeta$.
\item
    The branching mechanism $\psi: E\times[0,\infty) \to \mathbb R$ is given by
\begin{equation}
\label{eq: branching mechanism}
    \psi(x,z)=
    -\beta(x) z + \alpha (x) z^2 + \int_{(0,\infty)} (e^{-zy} - 1 + zy) \pi(x,dy).
\end{equation}
    where $\beta \in \mathcal B_b(E)$, $\alpha \in \mathcal B_b(E, \mathbb R_+)$ and $\pi(x,dy)$ is a kernel from $E$ to $(0,\infty)$ such that $\sup_{x\in E} \int_{(0,\infty)} (y\wedge y^2) \pi(x,dy) < \infty$.
\item
    $X=\{(X_t)_{t\geq 0}; (\mathbf P_\mu)_{\mu \in \mathcal M(E)}\}$ is an $\mathcal M(E)$-valued Hunt process with transition probability determined by
\begin{equation}
    \mathbf P_\mu [e^{-X_t(f)}] = e^{-\mu(V_tf)},
    \quad t\geq 0, \mu \in \mathcal M(E), f\in \mathcal B^+_b(E),
\end{equation}
    where for each $f\in \mathcal B_b(E)$, the function $(t,x)\mapsto V_tf(x)$ on $[0,\infty) \times E$ is the unique locally bounded positive solution to the equation
\begin{equation}\label{eq:FKPP_in_definition}
    V_tf(x) + \Pi_x \Big[  \int_0^{t\wedge \zeta} \psi(\xi_s,V_{t-s}f)ds \Big]
    = \Pi_x [ f(\xi_t)\mathbf 1_{t<\zeta} ],
    \quad t \geq 0, x \in E.
\end{equation}
\end{itemize}
    We refer our readers to \cite{Li2011Measure-valued} for more discussions about the definition and the existence of superprocesses.
    To avoid triviality, we assume that
    $\psi(x,z)$ is not identically equal to $-\beta(x)z$.

    Notice that the branching mechanism $\psi$ can be extended into a map from $E \times \mathbb C_+$ to $\mathbb C$ using \eqref{eq: branching mechanism}.
    Define
\begin{equation}
    \psi'(x,z):= - \beta(x) + 2\alpha(x) z + \int_{(0,\infty)} (1-e^{-zy})y\pi(x,dy),
    \quad x\in E, z\in \mathbb C_+.
\end{equation}
    Then according to Lemma \ref{lem: extension lemma for branching mechanism}, for each $x \in E$, $z \mapsto \psi(x,z)$ is a holomorphic function on $\mathbb C_+^0$ with derivative $z \mapsto \psi'(x,z)$.
    Define $\psi_0(x,z) := \psi(x,z)+ \beta(x)z $ and $\psi'_0(x,z) := \psi'(x,z) + \beta(x)$.
\end{comment}

    Denote by $\mathbb W$ the space of $\mathcal M(E)$-valued c\`{a}dl\`{a}g paths with its canonical path denoted by $(W_t)_{t\geq 0}$.
    We say our superprocess $X$ is \emph{non-persistent} if $\mathbf P_{\delta_x}(\|X_t\|= 0) > 0$ for all $x\in E$ and $t> 0$.
    Suppose that $(X_t)_{t\geq 0}$ is non-persistent, then according to \cite[Section 8.4]{Li2011Measure-valued}, there is a unique family of measures $(\mathbb N_x)_{x\in E}$ on $\mathbb W$ such that
\begin{itemize}
\item
    $\mathbb N_x (\forall t > 0, \|W_t\|=0) =0$;
\item
    $\mathbb N_x(\|W_0 \|\neq 0) = 0$;
\item
    For any $\mu \in \mathcal M(E)$, if $\mathcal N$ is a Poisson random measure defined on some probability space
    with intensity $\mathbb N_\mu(\cdot):= \int_E \mathbb N_x(\cdot )\mu(dx)$,
    then the superprocess $\{X;\mathbf P_\mu\}$ can be realized by $\widetilde X_0 := \mu$ and $\widetilde X_t(\cdot) := \mathcal N[W_t(\cdot)]$ for each $t>0$.
\end{itemize}
    We refer to $(\mathbb N_x)_{x\in E}$ as the \emph{Kuznetsov measures} of $X$.
\subsection{{Semigroups for superprocesses}}
\label{sec: definition of vf}
    Let $X$ be a non-persistent superprocess with its Kuznetsov measure denoted by $(\mathbb N_x)_{x\in E}$.
    We define the mean semigroup
\begin{equation}
    P_t^{\beta} f(x)
    := \Pi_{x}[e^{\int_0^t \beta(\xi_s)ds}f(\xi_t) \mathbf 1_{t< \zeta}],
    \quad t\geq 0, x\in E, f\in \mathcal B_b(E,\mathbb R_+).
\end{equation}
    It is known from \cite[Proposition 2.27]{Li2011Measure-valued} and \cite[Theorem 2.7]{Kyprianou2014Fluctuations} that for all $t > 0$, $\mu \in \mathcal M(E)$ and $f\in \mathcal B_b(E,\mathbb R_+)$,
\begin{equation}
\label{eq: mean formula for superprocesses}
   \mathbb N_{\mu}[\langle W_t, f\rangle]    
   =\mathbf P_{\mu}[\langle X_t, f\rangle]
   =\mu(P^{\beta}_t f).
\end{equation}

    Define
\begin{align}
    L_1(\xi)
    &:= \{f\in \mathcal B(E): \forall x\in E, t\geq 0, \quad \Pi_x[|f(\xi_t)|]< \infty\},
    \\L_2(\xi)
    &:= \{f \in \mathcal B(E): |f|^2 \in L_1(\xi)\}.
\end{align}
    Using monotonicity and linearity, we get from \eqref{eq: mean formula for superprocesses}  that
\begin{equation}
   \mathbb N_x[\langle W_t, f\rangle]   
    =\mathbf P_{\delta_x}[\langle f, X_t\rangle]
    =P^{\beta}_t f(x) \in \mathbb R,
    \quad f\in L_1(\xi), t > 0,x\in E.
\end{equation}
    This says that the random variable $\langle X_t, f\rangle$ is well defined under probability $\mathbf P_{\delta_x}$ provided $f\in L_1(\xi)$.
    By the branching property of the superprocess, $\langle X_t, f\rangle$ is an infinitely divisible random variable.
    Therefore, we can write
\[
    U_t(\theta f)(x) := \operatorname{Log} \mathbf P_{\delta_x}[e^{i \theta \langle X_t, f\rangle}],
    \quad t\geq 0, f\in L_1(\xi), \theta \in \mathbb R, x\in E,
\]
    as its characteristic exponent.
    According to Campbell's formula, see \cite[Theorem 2.7]{Kyprianou2014Fluctuations} for example, we have
\[
    \mathbf P_{\delta_x} [e^{i\theta \langle X_t, f\rangle}]
    = \exp(\mathbb N_x[ e^{i\theta \langle W_t, f\rangle} - 1]),
    \quad t>0, f\in L_1(\xi), \theta \in \mathbb R, x\in E.
\]
    Noticing that $\theta \mapsto \mathbb N_x[e^{i\theta W_t(f)} - 1]$ is a continuous function on $\mathbb R$ and that $\mathbb N_x[e^{i\theta \langle W_t, f\rangle} - 1] = 0$ if $\theta = 0$, according to \cite[Lemma 7.6]{Sato2013Levy}, we have
\begin{equation}
\label{eq: N and characteristic exponent}
    U_t(\theta f)(x) = \mathbb N_x[e^{i \langle W_t, \theta f\rangle} - 1],
    \quad t>0, f\in L_1(\xi), \theta \in \mathbb R, x\in E.
\end{equation}

\begin{lem}
    There exists constants $C\geq 0$ such that for all $f \in L_1(\xi),x\in E$ and $t\geq 0$, we have
\begin{equation}
\label{eq: upper bound of psi(v)}
    \big|\psi\big(x,-U_tf\big)\big|
    \leq C P^{\beta}_t |f|(x)+
         C (P^{\beta}_t |f| (x))^2.
\end{equation}
\end{lem}
\begin{proof}
     Noticing that
\[
    e^{\operatorname{Re} U_tf(x)}
    = |e^{U_tf(x)}|
    = |\mathbf P_{\delta_x}[e^{i \langle X_t, f\rangle}]|
    \leq 1,
\]
    we have
\begin{equation}
\label{eq: -v has positive real part}
 \operatorname{Re} U_tf(x)
    \leq 0.
\end{equation}
    Therefore, we can speak of $\psi(x,-U_tf)$ since $z\mapsto \psi(x,z)$ is well defined on $\mathbb C_+$.
    According to Lemma \ref{lem: estimate of exponential remaining}, we have that
\begin{equation}
\label{eq: upper bound for vf}
    |U_tf(x)| \leq \mathbb N_x[|e^{i \langle W_t, f\rangle} - 1|]
    \leq \mathbb N_x[|i \langle W_t, f\rangle|]
    \leq (P^{\beta}_t |f|)(x).
\end{equation}
    Notice that, for any compact $K \subset \mathbb R$,
\begin{equation}
\label{eq: estimate of deriavetive of v(theta)}
    \mathbb N_x\Big[\sup_{\theta \in K} \Big|\frac{\partial}{\partial \theta} (e^{i\theta \langle W_t, f\rangle} - 1) \Big|\Big]
    \leq \mathbb N_x[|\langle W_t, f\rangle|] \sup_{\theta \in K}|\theta|
    \leq (P^{\beta}_t |f|)(x) \sup_{\theta \in K}|\theta| < \infty.
\end{equation}
    Therefore, according to \cite[Theorem A.5.2]{Durrett2010Probability} and \eqref{eq: N and characteristic exponent},
    $U_t(\theta f)(x)$ is differentiable in $\theta \in \mathbb R$ with
\[
    \frac{\partial}{\partial \theta} U_t(\theta f)(x)
    = i\mathbb N_x[\langle W_t, f\rangle e^{i\theta \langle W_t, f\rangle}],
    \quad \theta \in \mathbb R.
\]
    Moreover, from the above, it is clear that
\begin{equation}
\label{eq: upper bounded for derivative of v(theta)}
    \sup_{\theta \in \mathbb R}\Big| \frac{\partial}{\partial \theta}U_t(\theta f)(x)\Big|
    \leq ( P^{\beta}_t |f|)(x).
\end{equation}
    It follows from the dominated convergence theorem that $(\partial/\partial \theta)U_t(\theta f)(x)$ is continuous in $\theta$.
    In other words, $\theta \mapsto -U_t(\theta f)(x)$ is a $C^1$ map from $\mathbb R$ to $\mathbb C_+$.
    Thus,
\begin{equation}
\label{eq: path integration representation of psi(v)}
    \psi(x,-U_tf)
    = -\int_0^1 \psi'\big(x,-U_t(\theta f)\big) \frac{\partial}{\partial \theta} U_t(\theta f)(x)~d\theta.
\end{equation}
    Notice that
\begin{align}
\label{eq: upper bound of psi'(v)}
    &|\psi'(x, -U_tf)|
    \\&= \Big| -\beta(x)- 2\alpha(x) U_tf(x)+ \int_{(0,\infty)} y (1- e^{y U_tf(x)} ) \pi(x,dy)\Big|
    \\&= \Big| - \beta(x)- 2\alpha(x)\mathbb N_x[e^{i \langle W_t, f\rangle} - 1]  + \int_{(0,\infty)} y \mathbf P_{y \delta_x}[1-e^{i \langle X_t, f\rangle}] \pi(x,dy) \Big|
    \\ &\leq \|\beta\|_\infty + 2\alpha(x)\mathbb N_x[\langle W_t, |f|\rangle]+ \int_{(0,\infty)} y\mathbf P_{y\delta_x}[2\wedge \langle X_t, |f|\rangle] \pi(x,dy)
    \\ &\leq \|\beta\|_\infty + 2\|\alpha\|_\infty
    P^{\beta}_t |f|(x) + \Big(\sup_{x\in E}\int_{(0,1]}y^2 \pi(x,dy)\Big)~P^{\beta}_t |f|(x) + 2\sup_{x\in E}\int_{(1,\infty)} y \pi(x,dy)
    \\ &=: C_1 + C_2(P^{\beta}_t |f|)(x),
\end{align}
    where $C_1, C_2$ are constants independent on $f,x$ and $t$.
    Now, combining \eqref{eq: path integration representation of psi(v)}, \eqref{eq: upper bounded for derivative of v(theta)} and \eqref{eq: upper bound of psi'(v)}, we get the desired result.
\end{proof}

    This lemma also says that if $f\in L^2(\xi)$ then
\[
    \Pi_x\Big[\int_0^t \psi(\xi_s,- U_{t-s}f)ds\Big]
    \in \mathbb C,
    \quad x\in E, t\geq 0.
\]
    is well defined.
    In fact, using Jensen's inequality and the Markov property, we have
\begin{align}
\label{eq: domination of psi(v)}
    &\Pi_x\Big[\int_0^t \big|\psi \big(\xi_s,-U_{t-s}f\big)\big|ds\Big]
    \\&\leq \Pi_x\Big[\int_0^t \big(C_1 P_{t-s}^{\beta}|f|(\xi_s)+C_2 P_{t-s}^{\beta}|f|(\xi_s)^2\big)ds\Big]
    \\ &\leq \int_0^t \big(C_1 e^{t\|\beta\|}\Pi_x \big[ \Pi_{\xi_s}[|f(\xi_{t-s})|] \big]+C_2 e^{2t\|\beta\|}\Pi_x \big[ \Pi_{\xi_s}[|f (\xi_{t-s})|]^2 \big]\big)~ds
    \\ &\leq \int_0^t (C_1 e^{t\|\beta\|}\Pi_x [ |f(\xi_{t})|]+C_2e^{2t\|\beta\|}\Pi_x [ |f (\xi_{t})|^2 ])~ds < \infty.
\end{align}

\section{Proof of the main result}
\begin{comment}
    Let $X$ be a non-persistent superprocess.
    In this subsection, we will prove the following:
\begin{prop}
\label{prop: complex FKPP-equation}
    If $f\in L_2(\xi)$,  then for all $t\geq 0$ and $x\in E$,
\begin{equation}
\label{eq: complex FKPP-equation}
    U_tf(x) - \Pi_x \Big[\int_0^t \psi\big(\xi_s, - U_{t-s}f\big) ds \Big]
    \\= i \Pi_x [f(\xi_t)]
\end{equation}
    and
\begin{equation}
\label{eq: complex FKPP-equation with FK-transform}
    U_tf(x) -  \int_0^t P_{t-s}^{\beta} \psi_0\big(\cdot,-U_sf\big) (x)~ds
    \\= iP_t^{\beta} f(x).
\end{equation}
\end{prop}
\end{comment}

    To prove the Proposition ?, we will need the generalized spine decomposition theorem from \cite{RenSongSun2017Spine}. 
    Let $f\in \mathcal B_b(E,\mathbb R_+)$, $T >0$ and $x\in E$.
    Suppose that $\mathbf P_{\delta_x}[\langle X_T, f\rangle] = \mathbb N_x[\langle W_T, f\rangle] = P^{\beta}_T f(x) \in (0,\infty)$, then we can define the following probability transforms:
\begin{equation}
    d\mathbf P_{\delta_x}^{\langle X_T, f\rangle}
    := \frac{\langle X_T, f\rangle}{P_T^{\beta} f(x)} d\mathbf P_{\delta_x};
    \quad d\mathbb N_x^{\langle W_T, f\rangle}
    :=  \frac{\langle W_T, f\rangle}{P_T^{\beta} f(x)} d\mathbb N_x.
\end{equation}
    Following the definition in \cite{RenSongSun2017Spine}, we say that $\{\xi, \mathbf n;\mathbf Q_{x}^{(f,T)}\}$ is a spine representation of $\mathbb N_x^{\langle W_T, f\rangle}$ if
\begin{itemize}
\item
    The spine process $\{(\xi_t)_{0\leq t\leq T}; \mathbf Q^{(f,T)}_x\}$ is a copy of $\{(\xi_t)_{0\leq t\leq T}; \Pi^{(f,T)}_{x}\}$,
    where
\begin{equation}
    d\Pi_x^{(f,T)} := \frac{f(\xi_T)e^{\int_0^T \beta(\xi_s)ds}}{P^{\beta}_T f(x)} d \Pi_x;
\end{equation}
\item
    Given $\{(\xi_t)_{0\leq t\leq T}; \mathbf Q^{(f,T)}_x\}$, the immigration measure 
%    $\{\mathbf n(\xi,ds,dw); \mathbf Q^{(f,T)}_x[\cdot |(\xi_t)_{0\leq t\leq T}]\}$ 
\[ \{\mathbf n(\xi,ds,dw); \mathbf Q^{(f,T)}_x[\cdot |(\xi_t)_{0\leq t\leq T}]\}\]
    is a Poisson random measure on $[0,T] \times \mathbb W$ with intensity
\begin{equation}
\label{eq: conditional intensity}
    \mathbf m(\xi,ds,dw)
    := 2 \alpha(\xi_s) ds \cdot \mathbb N_{\xi_s}(dw) + ds \cdot \int_{y\in (0,\infty)} y \mathbf P_{y\delta_{\xi_s}}(X\in dw) \pi(\xi_s,dy);
\end{equation}
\item
    $\{(Y_t)_{0\leq t\leq T}; \mathbf Q^{(f,T)}_x\}$ is an $\mathcal M(E)$-valued process defined by
\begin{equation}
    Y_t
    := \int_{(0,t] \times \mathbb W} w_{t-s} \mathbf n(\xi,ds,dw),
    \quad 0 \leq t\leq T.
\end{equation}
\end{itemize}
    According to the spine decomposition theorem in \cite{RenSongSun2017Spine}, we have that
\begin{equation}
\label{eq: Spine decomposition 1}
    \{(X_s)_{s \geq 0};\mathbf P_{\delta_x}^{\langle X_T, f\rangle}\}
    \overset{f.d.d.}{=} \{(X_s + W_s)_{s \geq 0};\mathbf P_{\delta_x} \otimes \mathbb N_x^{\langle W_T, f\rangle} \}
\end{equation}
    and
\begin{equation}
\label{eq: Spine decomposition 2}
    \{(W_s)_{0\leq s\leq T};\mathbb N_x^{\langle W_T, f\rangle}\}
    \overset{f.d.d.}{=} \{(Y_s)_{s \geq 0};\mathbf Q_x^{(f,T)}\}.
\end{equation}

\begin{proof}[Proof of Proposition \ref{prop: complex FKPP-equation}]
    Assume that $f\in \mathcal B_b(E)$.
    Fix $t>0, r\in [0,t), x\in E$ and a strictly positive $g\in \mathcal B_b(E)$.
    Denote by $\{\xi, \mathbf n; \mathbf Q_x^{(g,t)}\}$ the spine representation of $\mathbb N_x^{\langle W_t, g\rangle}$.
    Conditioned on $\{\xi; \mathbf Q_x^{(g,t)}\}$, denote by $\mathbf m(\xi, ds,dw)$ the conditional intensity of $\mathbf n$ in \eqref{eq: conditional intensity}.
    Denote by $\Pi_{r,x}$ the probability of Hunt process $\{\xi; \Pi\}$ initiated at time $r$ and position $x$.
    From Lemma \ref{lem: estimate of exponential remaining}, we have $\mathbf Q^{(g,t)}_{x}$-almost surely
\begin{align}
    &\int_{[0,t]\times \mathbb W}|e^{i \langle w_{t-s}, f\rangle} - 1| \mathbf m(\xi, ds,dw)
    \leq \int_{[0,t]\times \mathbb W}\big(| \langle w_{t-s}, f\rangle| \wedge 2\big) \mathbf m(\xi, ds,dw)
    \\&\leq \int_0^t \Big(2\alpha(\xi_s)\mathbb N_{\xi_s}\big( \langle W_{t-s}, |f|\rangle\big)  + \int_{(0,1]} y \mathbf P_{y \delta_{\xi_s}}[\langle X_{t-s}, |f|\rangle] \pi(\xi_s,dy)
    \\&\qquad\qquad+ 2\int_{(1,\infty)}y\pi(\xi_s,dy)\Big) ds
     \\&\leq \int_0^t (P_{t-s}^{\beta} |f|)(\xi_s)\Big(2\alpha(\xi_s)  + \int_{(0,1]} y^2 \pi(\xi_s,dy)\Big) ds + 2t \sup_{x\in E}\int_{(1,\infty)}y\pi(x,dy)
    \\&\leq \Big(2\|\alpha\|_\infty +\sup_{x\in E}\int_{(0,1]} y^2 \pi(x,dy)\Big) t e^{t\|\beta\|_\infty}\|f\|_\infty + 2t \sup_{x\in E}\int_{(1,\infty)}y\pi(x,dy)
    < \infty.
\end{align}
    Using this, Fubini's theorem, \eqref{eq: N and characteristic exponent} and \eqref{eq: -v has positive real part} we have $\mathbf Q^{(g,t)}_{x}$-almost surely,
\begin{align}
    &\int_{[0,t]\times \mathbb N}(e^{i \langle w_{t-s}, f\rangle} - 1) \mathbf m(\xi, ds,dw)
    \\&=\int_0^t \Big(2\alpha(\xi_s)\mathbb N_{\xi_s}(e^{i \langle W_{t-s}, f\rangle} - 1)  + \int_{(0,\infty)} y \mathbf P_{y \delta_{\xi_s}}[e^{i \langle X_{t-s}, f\rangle} - 1] \pi(\xi_s,dy)\Big) ds
    \\&=\int_0^t \Big( 2\alpha(\xi_s) U_{t-s} f(\xi_s) + \int_{(0,\infty)} y (e^{y U_{t-s}f(\xi_s)} - 1) \pi(\xi_s,dy) \Big) ds
    \\&= -\int_0^t \psi'_0 \big(\xi_s, -U_{t-s}f\big)ds.
\end{align}
    Therefore, according to \eqref{eq: Spine decomposition 2}, Campbell's formula and above, we have that
\begin{align}
\label{eq: N to Pi}
    \mathbb N_x^{\langle W_{t}, g\rangle}[e^{i \langle W_t, f\rangle}]
    &=\mathbf Q_x^{(g,t)} \Big[\exp\Big\{\int_{[0,t]\times \mathbb N}(e^{i \langle w_{t-s}, f\rangle} - 1) \mathbf m(\xi, ds,dw)\Big\}\Big]
    \\&= \Pi_x^{(g,t)} [e^{-\int_0^t \psi'_0(\xi_s, -U_{t-s}f)ds}]
    \\&= \frac{1}{P_t^{\beta} g (x)} \Pi_x[ g(\xi_t) e^{-\int_0^t \psi'(\xi_s, -U_{t-s}f)ds} ].
\end{align}
    Let $\epsilon >0$.
    Define $f^+ = (f \vee 0) + \epsilon$ and $f^- = (-f) \vee 0 + \epsilon$, then $f^\pm$ are strictly positive and $f = f^+ - f^-$.
    According to \eqref{eq: Spine decomposition 1}, we have that
\begin{equation}
    \frac{\mathbf P_{\delta_x}[\langle X_t,f^{\pm}\rangle e^{i \langle X_t,f\rangle}]}{\mathbf P_{\delta_x}[\langle X_t,f^{\pm}\rangle ]}
    = \mathbf P_{\delta_x}[e^{i \langle X_t,f\rangle}] \mathbb N_x^{\langle W_t,f^{\pm}\rangle}[e^{i \langle X_t,f\rangle}].
\end{equation}
    Using \eqref{eq: N to Pi} and the above, we have
\begin{align}
    \frac{\mathbf P_{\delta_x}[\langle X_t, f\rangle e^{i \langle X_t, f\rangle}] }{\mathbf P_{\delta_x}[e^{i \langle X_t, f\rangle}]}
    &= \mathbf P_{\delta_x}[\langle X_t, f^+\rangle] \mathbb N_x^{\langle W_t, f^+\rangle} [e^{i \langle X_t, f\rangle}] - \mathbf P_{\delta_x}[\langle X_t, f^-\rangle]\mathbb N_x^{\langle W_t, f^-\rangle}[e^{i \langle X_t, f\rangle}]
    \\& = \Pi_x[ f(\xi_t) e^{- \int_0^t \psi'(\xi_s, -U_{t-s}f) ds}  ].
\end{align}
    Therefore, we have
\begin{equation}
    \frac{\partial}{\partial \theta} {U_t(\theta f)(x)}
    = \frac{\mathbf P_{\delta_x}[i\langle X_t, f\rangle e^{i \langle X_t, f\rangle}] }{\mathbf P_{\delta_x}[e^{i \langle X_t, f\rangle}]}
    =  \Pi_x[ if(\xi_t) e^{ - \int_0^t \psi'(\xi_s, -U_{t-s}(\theta f)) ds} ].
\end{equation}
    Since $\{(\xi_{r+t})_{t \geq 0}; \Pi_{r,x}\} \overset{d}{=} \{(\xi_{t})_{t\geq 0}; \Pi_{x}\} $, we have

\begin{align}
    &\frac{\partial}{\partial \theta} U_{t-r}(\theta f)( x)
    = \Pi_x[ i f(\xi_{t-r}) e^{-\int_0^{t-r} \psi'(\xi_s, -U_{t-r-s}(\theta f)) ds} ]
    \\&= \Pi_{r,x}[i f(\xi_t)e^{-\int_0^{t-r} \psi'(\xi_{r+s}, -U_{t-r-s}(\theta f)) ds} ]
    = \Pi_{r,x}[if(\xi_t)e^{-\int_r^t \psi'(\xi_{s}, -U_{t-s}(\theta f)) ds} ].
\end{align}

    From \eqref{eq: upper bound of psi'(v)}, we know that for each $\theta\in \mathbb R$, $(t,x) \mapsto |\psi'(x,-U_tf(x))|$ is locally bounded (i.e. bounded on $[0,T]\times E$ for each $T \geq 0$).
    Therefore, we can apply Lemma \ref{eq: complex FK} and get that
\[
    \frac{\partial}{\partial \theta} U_{t-r}(\theta f)(x) + \Pi_{r,x} \Big[\int_r^t \psi'\big(\xi_s,- U_{t-s}(\theta f)\big)\frac{\partial}{\partial \theta} U_{t-s}(\theta f)(\xi_s)~ds\Big]
    = \Pi_{r,x} [i f(\xi_t)]
\]
    and
\begin{align}
    &\frac{\partial}{\partial \theta} U_{t-r}(\theta f)(x) + \Pi_{r,x} \Big[\int_r^t e^{\int_r^s \beta(\xi_u)du}\psi_0'\big(\xi_s,- U_{t-s}(\theta f)\big)\frac{\partial}{\partial \theta} U_{t-s}(\theta f)(\xi_s)~ds\Big]\\
    &= \Pi_{r,x} [i e^{\int_r^t \beta(\xi_s)ds}f(\xi_t)].
\end{align}
    Integrating the two displays above with respect to $\theta$  on [0,1], using \eqref{eq: path integration representation of psi(v)}, \eqref{eq: upper bound of psi'(v)}, \eqref{eq: upper bounded for derivative of v(theta)} and Fubini's theorem, we get
\begin{equation}
    U_{t-r}f(x) - \Pi_{r,x} \Big[\int_r^t \psi\big(\xi_s,-U_{t-s}f\big) ~ds\Big]
    = i\theta \Pi_{r,x} [f(\xi_t)]
\end{equation}
    and
\begin{equation}
    U_{t-r}f(x) - \Pi_{r,x} \Big[\int_r^t e^{\int_r^s \beta(\xi_u)du} \psi_0\big(\xi_s,- U_{t-s}f\big) ~ds\Big]
    = i\Pi_{r,x} [e^{\int_r^t\beta(\xi_u)du}f(\xi_t)].
\end{equation}
    Taking $r = 0$, we get that \eqref{eq: complex FKPP-equation} and \eqref{eq: complex FKPP-equation with FK-transform} are true if $f\in \mathcal B_b(E)$.

    The rest of the proof is to evaluate \eqref{eq: complex FKPP-equation} and \eqref{eq: complex FKPP-equation with FK-transform} for all $f\in L_2(\xi)$. We only do this for \eqref{eq: complex FKPP-equation} since the argument for \eqref{eq: complex FKPP-equation with FK-transform} is similar.
    Let $n \in \mathbb N$.
    Writing $f_n := (f^+ \wedge n) - (f^- \wedge n)$, then $f_n \xrightarrow[n\to \infty]{} f$ pointwise.
    From what we have proved, we have
\begin{equation}
\label{eq: complex FKPP-equation for fn}
    U_tf_n(x) - \Pi_{x} \Big[\int_0^t \psi\big(\xi_s, - U_{t-s}f_n\big) ~ds\Big]
    = i \Pi_{x} [f_n(\xi_t)].
\end{equation}
    Notice the following:
\begin{itemize}
\item
    It is clear that $\Pi_{x}[f_n(\xi_t)] \xrightarrow[n\to \infty]{} \Pi_{x}[f(\xi_t)]$.
\item
    $U_tf_n(x) \xrightarrow[n\to \infty]{} U_tf(x)$ due to \eqref{eq: N and characteristic exponent}, the dominated convergence theorem and the fact that
\[
    |e^{i W_t(f_n)} - 1| \leq \langle W_t, |f|\rangle;
    \quad \mathbb N_x[\langle W_t, |f|\rangle] = (P_t^{\beta} |f|)(x) < \infty.
\]
\item
    $\Pi_{x} [\int_0^t \psi(\xi_s,- U_{t-s}f_n)ds] \xrightarrow[n\to \infty]{} \Pi_{x} [\int_0^t \psi(\xi_s,- U_{t-s}f)ds]$ due to the dominated convergence theorem, \eqref{eq: domination of psi(v)} and the fact (see \eqref{eq: upper bound of psi(v)}) that
\begin{equation}
    \big|\psi(\xi_s,- U_{t-s}f_n)\big|
    \leq C_1 P_{t-s}^{\beta}|f|(\xi_s)+C_2 P_{t-s}^{\beta}|f|(\xi_s)^2.
\end{equation}
\end{itemize}
    Using the above arguments, letting $n \to \infty$ in \eqref{eq: complex FKPP-equation for fn}, we get the desired result.
\end{proof}

% vim:ts=4:sw=4
